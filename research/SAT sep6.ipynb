{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Kaitlyn Son\n",
    "# coding: utf-8\n",
    "\n",
    "import json\n",
    "import io\n",
    "import bz2\n",
    "import collections as coll\n",
    "import nltk\n",
    "from nltk.corpus import cmudict\n",
    "import string\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from string import maketrans\n",
    "import regex as re\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "py.sign_in('ks772', 'x27zf4qmhv') ## what is my u and key.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/Users/sports195admin/Desktop/rxch/SATGRE/SATwordsanddefs.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ca4029c97a89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## creating a SAT word list from a text file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msat_word_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/sports195admin/Desktop/rxch/SATGRE/SATwordsanddefs.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msat_word_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# add first word of every line to list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/Users/sports195admin/Desktop/rxch/SATGRE/SATwordsanddefs.txt'"
     ]
    }
   ],
   "source": [
    "## creating a SAT word list from a text file\n",
    "sat_word_list = []\n",
    "with open('/Users/sports195admin/Desktop/rxch/SATGRE/SATwordsanddefs.txt', 'r') as infile:\n",
    "    for line in infile:\n",
    "        sat_word_list.append(line.strip(\"\\n\").split()[0]) # add first word of every line to list\n",
    "\n",
    "\n",
    "## creating a GRE word list from a text file\n",
    "gre_word_list = []\n",
    "with open('/Users/sports195admin/Desktop/rxch/SATGRE/GREwordlist.txt', 'r') as infile:\n",
    "    for line in infile:\n",
    "        gre_word_list.append(line.strip(\"\\n\").split()[0]) # add first word of every line to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# removes punctuation\n",
    "# takes a string only tho \n",
    "def remove_punctuation(text):\n",
    "    #pat = re.compile(ur\"[\\p{P}\\p{S}]+\")\n",
    "    pat = re.compile(ur\"[\\p{P}\\p{S}](?<!-)+\")\n",
    "    return pat.sub(\"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "in_file_name = \"/Users/sports195admin/Downloads/success_timelines_00000.json.bz2\"\n",
    "out_file_name = \"/Users/sports195admin/Downloads/tweets_00000.json.bz2\"\n",
    "\n",
    "with bz2.BZ2File(in_file_name) as infile, bz2.BZ2File(out_file_name, 'w') as outfile:\n",
    "    list_of_sat_nums = []   \n",
    "    for line in infile: \n",
    "\n",
    "        first_tab = line.index(\"\\t\") # location of first tab char\n",
    "        first_tab\n",
    "        id = line[:first_tab]\n",
    "        id #users id\n",
    "\n",
    "        tweets = json.loads(line[first_tab:]) # creates a dict\n",
    "\n",
    "        user_id = tweets[u'user'][0][\"id_str\"] # gets user id as string\n",
    "\n",
    "        list_propics = [x['profile_image_url'] for x in tweets[u'user']]\n",
    "\n",
    "        list_desc = [x['description'] for x in tweets[u'user']]\n",
    "\n",
    "        list_tweets = [x['text'] for x in tweets[u'tweets']] # makes all the user's tweets into a list\n",
    "\n",
    "        tdict = coll.OrderedDict() \n",
    "        tdict[\"uid\"] = user_id\n",
    "        tdict[\"descriptions\"] = list_desc\n",
    "        tdict[\"texts\"] = list_tweets\n",
    "        tdict[\"pics\"] = list_propics\n",
    "\n",
    "        outfile.write(json.dumps(tdict)+'\\n')\n",
    "        \n",
    "        # goes thru every user and finds sat words\n",
    "        \n",
    "        sample = list_tweets\n",
    "\n",
    "        usable_sample = \"\"\n",
    "\n",
    "        ## strips all punctuation and makes everything lowercase \n",
    "        for line in sample:\n",
    "            usable_sample += remove_punctuation(line.lower())\n",
    "\n",
    "        sat_word_set = set(sat_word_list)\n",
    "\n",
    "        words = usable_sample.split() \n",
    "        print words \n",
    "\n",
    "        sat_word_count = sum(word in sat_word_set for word in words)\n",
    "\n",
    "        ####print sat_word_count\n",
    "        #%time\n",
    "        list_of_sat_nums.append(sat_word_count)\n",
    "\n",
    "#print list_of_sat_nums # this prints the list of all the \"Sat scores\" \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~ks772/25.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = list_of_sat_nums\n",
    "\n",
    "data = [\n",
    "    go.Histogram(\n",
    "        x=list_of_sat_nums\n",
    "    )\n",
    "]\n",
    "py.iplot(data)\n",
    "\n",
    "# look slike 120-170 is the most popular score\n",
    "\n",
    "## need percentage of sat words then plot it \n",
    "# find num of words in total\n",
    "# divide that by num sat words\n",
    "\n",
    "# use glob.glob to pull info from all files not just one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make a scatterplot of smog scores vs sat scores for users and compute the correlation.\n",
    "# gre version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
