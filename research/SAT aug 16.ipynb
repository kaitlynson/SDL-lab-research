{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Kaitlyn Son\n",
    "# coding: utf-8\n",
    "\n",
    "import json\n",
    "import io\n",
    "import bz2\n",
    "import collections as coll\n",
    "import nltk\n",
    "from nltk.corpus import cmudict\n",
    "import string\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as p\n",
    "from string import maketrans\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## creating a SAT word list from a text file\n",
    "sat_word_list = []\n",
    "with open('/Users/sports195admin/Desktop/rxch/SATGRE/SATwordsanddefs.txt', 'r') as infile:\n",
    "    for line in infile:\n",
    "        sat_word_list.append(line.strip(\"\\n\").split()[0]) # add first word of every line to list\n",
    "\n",
    "\n",
    "## creating a GRE word list from a text file\n",
    "gre_word_list = []\n",
    "with open('/Users/sports195admin/Desktop/rxch/SATGRE/GREwordlist.txt', 'r') as infile:\n",
    "    for line in infile:\n",
    "        gre_word_list.append(line.strip(\"\\n\").split()[0]) # add first word of every line to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## this is all old - until line 56\n",
    "in_file_name = \"/Users/sports195admin/Downloads/success_timelines_00000.json.bz2\"\n",
    "out_file_name = \"/Users/sports195admin/Downloads/tweets_00000.json.bz2\"\n",
    "\n",
    "with bz2.BZ2File(in_file_name) as infile, bz2.BZ2File(out_file_name, 'w') as outfile:\n",
    "\n",
    "\tfor line in infile: \n",
    "\n",
    "\t\tfirst_tab = line.index(\"\\t\") # location of first tab char\n",
    "\t\tfirst_tab\n",
    "\t\tid = line[:first_tab]\n",
    "\t\tid #users id\n",
    "\n",
    "\t\ttweets = json.loads(line[first_tab:]) # creates a dict\n",
    "\n",
    "\t\tuser_id = tweets[u'user'][0][\"id_str\"] # gets user id as string\n",
    "\n",
    "\t\tlist_propics = [x['profile_image_url'] for x in tweets[u'user']]\n",
    "\n",
    "\t\tlist_desc = [x['description'] for x in tweets[u'user']]\n",
    "\n",
    "\t\tlist_tweets = [x['text'] for x in tweets[u'tweets']] # makes all the user's tweets into a list\n",
    "\n",
    "\t\ttdict = coll.OrderedDict() \n",
    "\t\ttdict[\"uid\"] = user_id\n",
    "\t\ttdict[\"descriptions\"] = list_desc\n",
    "\t\ttdict[\"texts\"] = list_tweets\n",
    "\t\ttdict[\"pics\"] = list_propics\n",
    "\n",
    "\t\toutfile.write(json.dumps(tdict)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# removes punctuation\n",
    "# takes a string only tho \n",
    "def remove_punctuation(text):\n",
    "    #pat = re.compile(ur\"[\\p{P}\\p{S}]+\")\n",
    "    pat = re.compile(ur\"[\\p{P}\\p{S}](?<!-)+\")\n",
    "    return pat.sub(\"\", text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if you abase g-ave me a chance i abase would take itttt-its a shot in the dark but ill make itttworked out so hard today that it hurts getting in amp out of the truck 😊🔫called chel a bitch today sorry loveucan i have new friends🙋counting down the days till octoberhockeyseason 🐧sean amp i both ordered galaxy s5s today😀😀😀😀i am so impulsive 😩i have never been interested in shark week now i dont want to watch anything else sharkweek 🐠🐋🐳🐟\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##SAMPLE CELL for removing punctuation in sample text\n",
    "sample = [u\"if you Aba*se g-ave me a cha??nce i abase would take itttt\", u\"=-its a shot in the dark but I'{}|:>?+_!@#$%^&*()_ll make ittt\", u'Worked out so hard today that it hurts getting in &amp; out of the truck \\U0001f60a\\U0001f52b', u'Called chel a bitch today #sorry #loveu', u'Can I have new friends\\U0001f64b', u'Counting down the days till october....#hockeyseason \\U0001f427', u\"Sean &amp; I both ordered galaxy s5's today\\U0001f600\\U0001f600\\U0001f600\\U0001f600\", u'I am so impulsive \\U0001f629', u\"I have never been interested in shark week. Now I don't want to watch anything else #SharkWeek \\U0001f420\\U0001f40b\\U0001f433\\U0001f41f\"]\n",
    "\n",
    "usable_sample = \"\"\n",
    "\n",
    "## strips all punctuation and makes everything lowercase \n",
    "for line in sample:\n",
    "    usable_sample += remove_punctuation(line.lower())\n",
    "    \n",
    "print usable_sample\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "## SAMPLE CELL for finding num of times sat words used in sample text\n",
    "\n",
    "sat_word_set = set(sat_word_list)\n",
    "\n",
    "words = usable_sample.split() \n",
    "\n",
    "sat_word_count = sum(word in sat_word_set for word in words)\n",
    "\n",
    "print sat_word_count\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "543\n"
     ]
    }
   ],
   "source": [
    "# goes through first users tweets, strips punct and counts number of sat words used in 1 user's text. \n",
    "\n",
    "sample = list_tweets\n",
    "\n",
    "usable_sample = \"\"\n",
    "\n",
    "## strips all punctuation and makes everything lowercase \n",
    "for line in sample:\n",
    "    usable_sample += remove_punctuation(line.lower())\n",
    "    \n",
    "sat_word_set = set(sat_word_list)\n",
    "\n",
    "words = usable_sample.split() \n",
    "\n",
    "sat_word_count = sum(word in sat_word_set for word in words)\n",
    "\n",
    "print sat_word_count\n",
    "#%time\n",
    "\n",
    "\n",
    "#intersection = sat_word_set & set(words)\n",
    "#print intersection\n",
    "#print len(intersection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
