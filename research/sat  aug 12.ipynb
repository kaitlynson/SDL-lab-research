{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Kaitlyn Son\n",
    "# coding: utf-8\n",
    "\n",
    "import json\n",
    "import io\n",
    "import bz2\n",
    "import collections as coll\n",
    "import nltk\n",
    "from nltk.corpus import cmudict\n",
    "import string\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as p\n",
    "from string import maketrans\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## creating a SAT word list from a text file\n",
    "sat_word_list = []\n",
    "with open('/Users/sports195admin/Desktop/word_comp/SATwordsanddefs.txt', 'r') as infile:\n",
    "    for line in infile:\n",
    "        sat_word_list.append(line.strip(\"\\n\").split()[0]) # add first word of every line to list\n",
    "\n",
    "\n",
    "## creating a GRE word list from a text file\n",
    "gre_word_list = []\n",
    "with open('/Users/sports195admin/Desktop/word_comp/GREwordlist.txt', 'r') as infile:\n",
    "    for line in infile:\n",
    "        gre_word_list.append(line.strip(\"\\n\").split()[0]) # add first word of every line to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## this is all old - until line 56\n",
    "in_file_name = \"/Users/sports195admin/Downloads/success_timelines_00000.json.bz2\"\n",
    "out_file_name = \"/Users/sports195admin/Downloads/tweets_00000.json.bz2\"\n",
    "\n",
    "with bz2.BZ2File(in_file_name) as infile, bz2.BZ2File(out_file_name, 'w') as outfile:\n",
    "\n",
    "\tfor line in infile: \n",
    "\n",
    "\t\tfirst_tab = line.index(\"\\t\") # location of first tab char\n",
    "\t\tfirst_tab\n",
    "\t\tid = line[:first_tab]\n",
    "\t\tid #users id\n",
    "\n",
    "\t\ttweets = json.loads(line[first_tab:]) # creates a dict\n",
    "\n",
    "\t\tuser_id = tweets[u'user'][0][\"id_str\"] # gets user id as string\n",
    "\n",
    "\t\tlist_propics = [x['profile_image_url'] for x in tweets[u'user']]\n",
    "\n",
    "\t\tlist_desc = [x['description'] for x in tweets[u'user']]\n",
    "\n",
    "\t\tlist_tweets = [x['text'] for x in tweets[u'tweets']] # makes all the user's tweets into a list\n",
    "\n",
    "\t\ttdict = coll.OrderedDict() \n",
    "\t\ttdict[\"uid\"] = user_id\n",
    "\t\ttdict[\"descriptions\"] = list_desc\n",
    "\t\ttdict[\"texts\"] = list_tweets\n",
    "\t\ttdict[\"pics\"] = list_propics\n",
    "\n",
    "\t\toutfile.write(json.dumps(tdict)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# another way to remove punc. unicode way - remvs all punc\n",
    "# only leaves hyphens\n",
    "# takes a string only tho \n",
    "def remove_punctuation(text):\n",
    "    #pat = re.compile(ur\"[\\p{P}\\p{S}]+\")\n",
    "    pat = re.compile(ur\"[\\p{P}\\p{S}](?<!-)+\")\n",
    "    return pat.sub(\"\", text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if you abase g-ave me a chance i would take itttt-its a shot in the dark but ill make itttworked out so hard today that it hurts getting in amp out of the truck üòäüî´called chel a bitch today sorry loveucan i have new friendsüôãcounting down the days till octoberhockeyseason üêßsean amp i both ordered galaxy s5s todayüòÄüòÄüòÄüòÄi am so impulsive üò©i have never been interested in shark week now i dont want to watch anything else sharkweek üê†üêãüê≥üêü\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##SAMPLE CELL\n",
    "sample = [u\"if you Aba*se g-ave me a cha??nce i would take itttt\", u\"=-its a shot in the dark but I'{}|:>?+_!@#$%^&*()_ll make ittt\", u'Worked out so hard today that it hurts getting in &amp; out of the truck \\U0001f60a\\U0001f52b', u'Called chel a bitch today #sorry #loveu', u'Can I have new friends\\U0001f64b', u'Counting down the days till october....#hockeyseason \\U0001f427', u\"Sean &amp; I both ordered galaxy s5's today\\U0001f600\\U0001f600\\U0001f600\\U0001f600\", u'I am so impulsive \\U0001f629', u\"I have never been interested in shark week. Now I don't want to watch anything else #SharkWeek \\U0001f420\\U0001f40b\\U0001f433\\U0001f41f\"]\n",
    "\n",
    "usable_sample = \"\"\n",
    "\n",
    "## strips all punctuation and makes everything lowercase \n",
    "for line in sample:\n",
    "    usable_sample += remove_punctuation(line.lower())\n",
    "    \n",
    "print usable_sample\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'list_of_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-99dd4930944a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msat_word_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msat_word_list\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_of_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0msat_word_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# list_of_words = []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'list_of_words' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "set([u'course', u'ground', u'console', u'personal', u'pharmacy', u'finally', u'compensate', u'personality', u'possible', u'facial', u'difference', u'investigator', u'fragile', u'explode', u'notorious', u'guy', u'beneficial', u'inconsequential', u'likely', u'expect', u'exuberant', u'affable', u'peter', u'alcohol', u'definite', u'encourage', u'mischievous', u'hilarious', u'medicine', u'dominate', u'forth', u'bass', u'makeup', u'free', u'quite', u'pleasant', u'expansion', u'craving', u'annual', u'quiet', u'sensitive', u'positive', u'opinion', u'protector', u'secretive', u'guess', u'illegal', u'scope', u'mundane', u'head', u'amateur', u'successful', u'ridiculous', u'tense', u'excellent', u'off', u'believe', u'pageant', u'edible', u'aspiration', u'matter', u'harmonious', u'abrupt', u'duet', u'spontaneous', u'perspective', u'control', u'urban', u'recognize', u'influence', u'cant', u'sense', u'ready', u'lifetime', u'element', u'disappear', u'productive', u'perhaps', u'belle', u'emphasis', u'potential', u'disappoint', u'reckless', u'finale', u'impulsive', u'audition', u'significant', u'icon', u'finesse', u'reflection', u'enthusiastic', u'later', u'doe', u'came', u'lying', u'typical'])\n"
     ]
    }
   ],
   "source": [
    "# goes thru first users tweets\n",
    "\n",
    "sample = list_tweets\n",
    "\n",
    "punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*1234567890_~'''\n",
    "\n",
    "usable_sample = []\n",
    "\n",
    "for line in sample:\n",
    "    lowercase_line = line.lower()\n",
    "    no_punc = \"\"\n",
    "    for char in lowercase_line:\n",
    "        if char not in punctuations:\n",
    "            no_punc += char     \n",
    "    usable_sample.append(no_punc)\n",
    "list_of_words = []\n",
    "for element in usable_sample:\n",
    "    list_of_words += element.split() # creates list where each element is a word\n",
    "#prints the sat words in text\n",
    "intersection = set(sat_word_list) & set(list_of_words)\n",
    "print len(intersection)\n",
    "print intersection \n",
    "#%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for word in sat_word_list:\n",
    "#     if not word.lower() == remove_punctuation(word.lower()):\n",
    "#         print word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for word in gre_word_list:\n",
    "#     if not word.lower() == remove_punctuation(word.lower()):\n",
    "#         print word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove_punctuation(\"blas√©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
