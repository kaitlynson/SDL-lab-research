{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "import bz2\n",
    "import collections as coll\n",
    "import nltk\n",
    "from nltk.corpus import cmudict\n",
    "import string\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from string import maketrans\n",
    "import regex as re\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "py.sign_in('ks772', 'x27zf4qmhv')\n",
    "import itertools as itr\n",
    "import glob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ## creating a SAT word list from a text file\n",
    "# sat_word_list = []\n",
    "# with open('/Users/sports195admin/Desktop/rxch/github/research/SATGRE/SATWords.txt', 'r') as infile:\n",
    "#     for line in infile:\n",
    "#         sat_word_list.append(line.strip(\"\\n\").split()[0]) # add first word of every line to list\n",
    "\n",
    "\n",
    "# creating a GRE word list from a text file\n",
    "sat_word_list = []\n",
    "#### CHANGET THIS TO GRE_\n",
    "with open('/Users/sports195admin/Desktop/rxch/github/research/SATGRE/GREwords.txt', 'r') as infile:\n",
    "    for line in infile:\n",
    "        sat_word_list.append(line.strip(\"\\n\").split()[0]) # add first word of every line to list\n",
    "### CHANGE THIS TO GRE_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# removes punctuation\n",
    "# takes a string only tho \n",
    "def remove_punctuation(text):\n",
    "    #pat = re.compile(ur\"[\\p{P}\\p{S}]+\")\n",
    "    pat = re.compile(ur\"[\\p{P}\\p{S}](?<!-)+\")\n",
    "    return pat.sub(\"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_file_name = \"/Users/sports195admin/Downloads/success_timelines_00000.json.bz2\"\n",
    "out_file_name = \"/Users/sports195admin/Downloads/tweets_00000.json.bz2\"\n",
    "\n",
    "with bz2.BZ2File(in_file_name) as infile, bz2.BZ2File(out_file_name, 'w') as outfile:\n",
    "    list_of_sat_nums = []   \n",
    "    list_of_sat_percents = []\n",
    "\n",
    "    for line in infile: \n",
    "\n",
    "        first_tab = line.index(\"\\t\") # location of first tab char\n",
    "        first_tab\n",
    "        id = line[:first_tab]\n",
    "        id #users id\n",
    "\n",
    "        tweets = json.loads(line[first_tab:]) # creates a dict\n",
    "\n",
    "        user_id = tweets[u'user'][0][\"id_str\"] # gets user id as string\n",
    "\n",
    "        list_propics = [x['profile_image_url'] for x in tweets[u'user']]\n",
    "\n",
    "        list_desc = [x['description'] for x in tweets[u'user']]\n",
    "\n",
    "        list_tweets = [x['text'] for x in tweets[u'tweets']] # makes all the user's tweets into a list\n",
    "\n",
    "        tdict = coll.OrderedDict() \n",
    "        tdict[\"uid\"] = user_id\n",
    "        tdict[\"descriptions\"] = list_desc\n",
    "        tdict[\"texts\"] = list_tweets\n",
    "        tdict[\"pics\"] = list_propics\n",
    "\n",
    "        outfile.write(json.dumps(tdict)+'\\n')\n",
    "        \n",
    "        # goes thru every user and finds sat words\n",
    "        \n",
    "        sample = list_tweets\n",
    "\n",
    "        usable_sample = \"\"\n",
    "                \n",
    "        for line in sample:\n",
    "            usable_sample += remove_punctuation(line.lower()) # removes all punct and makes evrything lower\n",
    "\n",
    "        sat_word_set = set(sat_word_list)\n",
    "\n",
    "        words = usable_sample.split() \n",
    "        sat_word_count = sum(word in sat_word_set for word in words)\n",
    "\n",
    "        ####print sat_word_count\n",
    "        #%time\n",
    "        list_of_sat_nums.append(sat_word_count)\n",
    "        \n",
    "        num_total_words = len(words)\n",
    "        num_sat_words = len(list_of_sat_nums)\n",
    "        sat_percentage = (float(num_sat_words) / num_total_words) * 100\n",
    "        list_of_sat_percents.append(sat_percentage)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make data table for sat percentage gre percentage and smog scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make graph for all three too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### how do i take all these of these programs and merge them into one..?? do i put them all in diff functions? how should that work in python? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    create_sat_list()\n",
    "    create_gre_list()\n",
    "    remove_punc()\n",
    "    open_file()\n",
    "    calc_sat_percent()\n",
    "    calc_gre_percent()\n",
    "    is_three_plus_syllables()\n",
    "    count_poly_syllables()\n",
    "    count_sents()\n",
    "    compute_smog_score()\n",
    "    create_dt()\n",
    "    plot_histogram() \n",
    "    \n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a word matching function (see below. adapt code. new vars.)\n",
    "# change gre and sat counter finder\n",
    "# look up/implement stemming function on nltk - stem every sat word and every word in timeline and then compare stemmed text words to stemmed sat words\n",
    "# update to python 3? (prints needs parenthesis in py3)\n",
    "\n",
    "# textstats is a package that counts syllables - but might not work on python 3? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def word_match_counter(clean_words, word_set_dict):\n",
    "#     result = {k:0 for k in word_set_dict}\n",
    "#     total_count = len(clean_words)\n",
    "#     word_counter = coll.Counter(clean_words)\n",
    "#     for word, count in word_counter.items():\n",
    "#         for k, v in word_set_dict.items():\n",
    "#             if word in v:\n",
    "#                 print(word)\n",
    "#                 result[k] += count\n",
    "#     print(result)            \n",
    "#     return {k:v/total_count for k,v in result.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports\n",
    "\n",
    "lower\n",
    "strip\n",
    "stem\n",
    "clean\n",
    "    lower\n",
    "    strip\n",
    "    stem\n",
    "isthere3syllbs\n",
    "countpolly\n",
    "sountsents\n",
    "computesmogscore\n",
    "createsatlist\n",
    "    clean\n",
    "creategrelist\n",
    "    clean\n",
    "openfiles\n",
    "    computesmogscore\n",
    "    clean\n",
    "wordmatchcounter\n",
    "\n",
    "def main():\n",
    "    isthere3syllbs\n",
    "    countpolly\n",
    "    sountsents\n",
    "    computesmogscore\n",
    "    createsatlist\n",
    "    creategrelist\n",
    "    openfiles\n",
    "    computesmogscore\n",
    "    wordmatchcounter\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def stem_remover(word_list):\n",
    "#     new_list = []\n",
    "#     stemmer = SnowballStemmer(\"english\")\n",
    "#     for word in word_list:\n",
    "#         new_word = stemmer.stem(word)\n",
    "#         new_list.append(new_word)\n",
    "#     return new_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
